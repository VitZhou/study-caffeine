{"./":{"url":"./","title":"Introduction","keywords":"","body":"Caffeine 学习笔记 导航 Caffeine是一个高性能的基于jdk8的缓存库 官网 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-07 15:50:41 "},"caffeine/home.html":{"url":"caffeine/home.html","title":"Home","keywords":"","body":"Home Caffeine是一个高性能的基于jdk8的缓存库,提供了接近最佳的命中率。 缓存也ConcurrentMap类似,但是并不完全相同.最重要的区别是:1.ConcurrentMap会持久化它所包含的所有的元素,直到它们被明确的删除.2.高速缓存一般配置为自动删除元素，以限制其内存占用.在某些情况下,由于LoadCache或AsyncLoadingCache可以自动缓存加载所以即使它不能驱逐条目也可以使用。 Caffeine提供了灵活的结构用于创建缓存和以下功能组合: 自动加载条目到缓存中,提供可选异步 基于size的驱逐: 当超过最大值时会驱逐使用频率最高或最近一次使用的条目 基于时间的驱逐: 通过上次访问或者上次写入的时间来测量 异步刷新: 当发生第一个过时请求时进行异步刷新. key自动包装在弱引用中 value自动包装在弱或软引用中 通知被驱逐(或其他方式删除)的条目 统计缓存的访问 写操作可以通过外部资源传播 为了方便集成，在扩展模块中提供了JSR-107 JCache和Guava适配器。 JSR-107标准化了基于Java 6的API，以特性和性能为代价来最小vendor的特定代码。 Guava的cache是其predecessor库，适配器提供了一个简单的迁移策略。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-07 11:32:31 "},"caffeine/caches/population.html":{"url":"caffeine/caches/population.html","title":"Cache","keywords":"","body":"成员 Caffeine提供三种类型的成员加载策略：手动，同步加载和异步加载。 手动 Cache cache = Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .maximumSize(10_000) .build(); //查找条目,如果找不到则返回null Graph graph = cache.getIfPresent(key); //如果在缓存中不存在则查找并计算,如果不可计算则返回null graph = cache.get(key, k -> createExpensiveGraph(key)); // 添加或更新条目 cache.put(key, graph); // 移除条目 cache.invalidate(key); Cache接口允许显示的控制检索,更新和移除条目 可以直接使用cache.put(key,value)将条目插入到缓存中.这将覆盖指定key在缓存中以前的条目.尽量使用cache.get(key,v->value)自动计算并将值插入缓存,以避免其他写入竞争.请注意,如果条目不可计算,则cache.get可能返回Null,如果计算失败,则可能会抛出异常。 也可以使用由cache.asMap()暴露的ConcurrentMap的任何方法对缓存进行更改。 同步加载 LoadingCache cache = Caffeine.newBuilder() .maximumSize(10_000) .expireAfterWrite(10, TimeUnit.MINUTES) .build(key -> createExpensiveGraph(key)); //如果在缓存中不存在则查找并计算,如果不可计算则返回null Graph graph = cache.get(key); //查找并计算不存在的条目 Map graphs = cache.getAll(keys); LoadingCache是使用附加的CacheLoader构建的缓存。 批量查找可以使用getAll方法执行。 默认情况下，getAll将对缓存中没有的每个key分别调用CacheLoader.load。 当批量检索比许多单独的查找更有效时，您可以重写CacheLoader.loadAll。 请注意，您可以编写一个CacheLoader.loadAll实现，为未特别请求的key加载值。 例如，如果计算某个组中的任何key的值将为该组中的所有key提供值，则loadAll可能会同时加载该组的其余部分。 异步加载 AsyncLoadingCache cache = Caffeine.newBuilder() .maximumSize(10_000) .expireAfterWrite(10, TimeUnit.MINUTES) // Either: 使用包装为异步的同步计算进行构建 .buildAsync(key -> createExpensiveGraph(key)); // Or: 构建一个返回future的异步计算 .buildAsync((key, executor) -> createExpensiveGraphAsync(key, executor)); // 如果缓存中不存在,则查找并异步计算条目 CompletableFuture graph = cache.get(key); //查找并异步计算不存在的条目 CompletableFuture> graphs = cache.getAll(keys); AsyncLoadingCache是一个LoadingCache变体，用于计算Executor上的条目并返回CompletableFuture。 这是允许使用流行的响应式编程模型的缓存。 当计算以同步方式表示更好时，应提供CacheLoader。 当计算异步表示更好时，应该提供一个AsyncCacheLoader，并返回一个CompletableFuture。 synchronous()提供了一个阻塞直到异步计算完成的视图. 默认执行程序是ForkJoinPool.commonPool()，可以通过Caffeine.executor(Executor)覆盖。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-07 14:55:35 "},"caffeine/caches/eviction.html":{"url":"caffeine/caches/eviction.html","title":"驱逐","keywords":"","body":"驱逐(Eviction) Caffeine提供三种类型的驱逐：基于size的驱逐，基于时间的驱逐和基于引用的驱逐。 基于size //基于高速缓存中条目的数量进行驱逐 LoadingCache graphs = Caffeine.newBuilder() .maximumSize(10_000) .build(key -> createExpensiveGraph(key)); // 基于高速缓存中vertices的数量进行回退 LoadingCache graphs = Caffeine.newBuilder() .maximumWeight(10_000) .weigher((Key key, Graph graph) -> graph.vertices().size()) .build(key -> createExpensiveGraph(key)); 如果您的缓存不应超过一定的大小，请使用Caffeine.maximumSize(long)。 缓存将试图驱逐最近或最经常使用的条目。 或者，如果不同的缓存条目具有不同的“权重”（例如，如果缓存value具有完全不同的内存占用情况），则可以使用Caffeine.weigher(Weigher)指定权重函数，并使用Caffeine.maximumWeight(long)。 除了与maximumSize要求相同的警告外，请注意，需要在创建条目和更新时计算权重，此后是静态的，并且在进行驱逐选择时不使用相对权重。 基于时间 // 基于固定的到期策略进行退出 LoadingCache graphs = Caffeine.newBuilder() .expireAfterAccess(5, TimeUnit.MINUTES) .build(key -> createExpensiveGraph(key)); LoadingCache graphs = Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .build(key -> createExpensiveGraph(key)); // 基于不同的到期策略进行退出 LoadingCache graphs = Caffeine.newBuilder() .expireAfter(new Expiry() { public long expireAfterCreate(Key key, Graph graph, long currentTime) { // 如果来自外部资源，则使用挂钟时间，而不是使用纳米时间 long seconds = graph.creationDate().plusHours(5) .minus(System.currentTimeMillis(), MILLIS) .toEpochSecond(); return TimeUnit.SECONDS.toNanos(seconds); } public long expireAfterUpdate(Key key, Graph graph, long currentTime, long currentDuration) { return currentDuration; } public long expireAfterRead(Key key, Graph graph, long currentTime, long currentDuration) { return currentDuration; } }) .build(key -> createExpensiveGraph(key)); Caffeine提供三种方法来定时驱逐: expireAfterAccess(long, TimeUnit): 自条目最后一次读取或写入以来经过指定的时间后，将条目过期。 适用于如存的数据绑定到会话并由于不活动而过期的场景。 expireAfterWrite(long, TimeUnit): 自创建条目以来或最近一次的值替换经过了指定的时间长度之后的到期条目。 适用于缓存的数据在一段时间后延长时间的场景。 expireAfter(Expiry): 在变量持续时间过后，将条目过期。 当条目的到期时间由外部资源确定时，适合这种方式。 在写入期间定期进行维护，偶尔在读取期间执行到期。 计划和触发到期事件是在O(1)时间内执行的。 测试定时驱逐不要求测试等到挂钟时间结束。 使用Ticker接口和Caffeine.ticker（Ticker）方法在缓存生成器中指定时间源，而不必等待系统时钟。 基于引用 // 在没有key和值都无法到达的情况下退出 LoadingCache graphs = Caffeine.newBuilder() .weakKeys() .weakValues() .build(key -> createExpensiveGraph(key)); // 当垃圾收集器需要释放内存时退出 LoadingCache graphs = Caffeine.newBuilder() .softValues() .build(key -> createExpensiveGraph(key)); Caffeine允许你对键或值使用弱引用，以及对值使用软引用来设置你的缓存以便允许gc回收条目。请注意，AsyncLoadingCache不支持弱和软引用值。 Caffeine.weakKeys()使用弱引用存储key。这允许条目被垃圾收集，如果没有其他强引用的key。由于垃圾收集只依赖于identity是否相等，因此这会导致整个缓存使用identity（==）相等来比较key，而不是使用equals()。 Caffeine.weakValues()使用弱引用存储值。这允许条目被垃圾回收，如果没有其他强引用的直。由于垃圾收集只依赖于identity是否相等，因此这会导致整个缓存使用identity（==）相等来比较key，而不是使用equals()。 Caffeine.softValues()使用软引用存储值。为了响应内存需求，软引用的对象以全局最近最少使用的方式进行垃圾收集。由于使用软引用的性能影响，我们通常建议使用更可预测的基于size的最大高速缓存size。 softValues()的使用将使得使用identity（==）相等而不是equals（）来比较值。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 09:46:37 "},"caffeine/caches/removal.html":{"url":"caffeine/caches/removal.html","title":"移除","keywords":"","body":"移除(Removal) 术语: 驱逐(eviction)意味着由于策略的原因退出 失效(invalidation)表示手动移除 移除(removal)由驱逐和失效而产生的 显式的移除 在任何时候你都可以显式的使缓存中的条目失效,而无须等待条目由于策略被驱逐. // individual key cache.invalidate(key) // bulk keys cache.invalidateAll(keys) // all keys cache.invalidateAll() 移除监听 Cache graphs = Caffeine.newBuilder() .removalListener((Key key, Graph graph, RemovalCause cause) -> System.out.printf(\"Key %s was removed (%s)%n\", key, cause)) .build(); 你可以通过Caffeine.removalListener(RemovalListener)为缓存指定一个移除监听器,以便在删除条目时执行某些操作. RemovalListener获取key，value和RemovalCause。 移除监听器是使用Executor异步执行的.默认执行程序是ForkJoinPool.commonPool(),可以通过Caffeine.executor(Executor)覆盖.当操作必须与删除同步执行时，请改为使用CacheWriter。 请注意，由RemovalListener抛出的任何异常都会被记录（使用Logger）并被吞下。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 10:00:24 "},"caffeine/caches/refresh.html":{"url":"caffeine/caches/refresh.html","title":"刷新","keywords":"","body":"刷新 LoadingCache graphs = Caffeine.newBuilder() .maximumSize(10_000) .refreshAfterWrite(1, TimeUnit.MINUTES) .build(key -> createExpensiveGraph(key)); 刷新跟驱逐不同,例如LoadingCache.refresh(K)会为key异步的加载新的值(如果有旧值那么刷新key的时候任然会被返回,但是检索会异步的等待直到重新加载该值). 与expireAfterWrite不同的是，refreshAfterWrite将在指定的持续时间之后使key符合刷新的条件，但刷新只会在查询条目时才会触发。因此，您可以在同一个缓存中同时指定refreshAfterWrite和expireAfterWrite，那么只要条目有资格进行刷新，就不会盲目重置。 如果条目在刷新后没有被查询，则允许到期。 CacheLoader可以通过覆盖CacheLoader.reload(K，V)来指定在刷新行为，这允许您在计算新值时使用旧值。 刷新操作是使用Executor异步执行的。 默认执行程序是ForkJoinPool.commonPool()，可以通过Caffeine.executor（Executor）覆盖。 如果刷新时引发异常，则保留旧值并记录异常（使用logger）并吞掉。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 10:40:31 "},"caffeine/caches/writer.html":{"url":"caffeine/caches/writer.html","title":"Writer","keywords":"","body":"Writer LoadingCache graphs = Caffeine.newBuilder() .writer(new CacheWriter() { @Override public void write(Key key, Graph graph) { // write to storage or secondary cache } @Override public void delete(Key key, Graph graph, RemovalCause cause) { // delete from storage or secondary cache } }) .build(key -> createExpensiveGraph(key)); CacheWriter允许缓存充当底层资源的门面(开闭原则)，当与CacheLoader结合使用时，所有的读写操作都可以通过缓存进行传播。Writer将缓存中的原子操作扩展为同步加载外部资源。这意味着缓存将阻止对条目的后续变更操作,并且读操作会返回先前的旧值,直到写入的完成.如果写入程序失败,那么银蛇保持不变.抛出的异常会传递给调用者。 CacheWriter会在创建，变更或删除条目时得到通知。加载(例如，LoadingCache.get)，重新加载(例如，LoadingCache.refresh)或计算(例如Map.computeIfPresent)将不被告知。 请注意，CacheWriter不能与弱引用key或AsyncLoadingCache结合使用。 可能的用例 CacheWriter是复杂工作流的扩展点，需要外部资源来观察给定键的变化顺序。 这些用法是Caffeine支持，但不是本地内置。 write模式 一个CacheWriter可能被用来实现一个write-through或write-back缓存。 在write-through(直接写)模式高速缓存中，操作是同步执行的，只有在Writer成功完成后才会更新高速缓存。 这样可以避免资源和缓存分别作为独立的原子操作进行更新的争用情况。 在write-back(回写)式高速缓存中，在高速缓存更新之后，对外部资源的操作是异步执行的。 这可以提高写入吞吐量，避免数据不一致的风险，例如写入失败时在缓存中保留无效状态。 这种方法可能有助于延迟写入(直到特定时间)，限制写入速率或批量写入操作。 write-back回写式扩展可能实现以下部分或全部功能： 批处理和合并操作 在时间窗口内延迟操作 如果超过阈值大小，则在定期刷新之前执行批处理 如果操作尚未刷新，则从write-behind缓冲加载 根据外部资源的特点，处理重审，速率限制和并发 有关使用RxJava的简单示例，请参阅write-behind-rxjava。 分层 一个CacheWriter可能被用来集成多个缓存层。 分层缓存加载和写入由system record的外部缓存支持。 允许有一个小的快速缓存，回落(falls back)慢的大缓存。 典型的层次是堆外，基于文件和远程缓存。 victim缓存是一个分层变体，其中被逐出的条目被写入二级缓存。 delete(K，V，RemovalCause)允许检查为什么该条目被删除，并作出相应的反应。 同步监听 CacheWriter可用于发布到同步侦听器。 同步侦听器按照给定key在缓存上的操作顺序接收事件通知。 监听器可以阻止缓存操作，也可以将事件排队以异步执行。 这种类型的侦听器最常用于复制或构建分布式缓存。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 14:06:17 "},"caffeine/caches/statistics.html":{"url":"caffeine/caches/statistics.html","title":"统计","keywords":"","body":"统计 Cache graphs = Caffeine.newBuilder() .maximumSize(10_000) .recordStats() .build(); 通过使用Caffeine.recordStats()，你可以打开统计信息收集。Cache.stats()方法返回提供统计信息的CacheStats，如: hitRate(): 返回请求命中率 evictionCount(): 缓存逐出成员的数量 averageLoadPenalty(): 加载新值所花费的平均时间 这些统计数据对缓存调整至关重要，我们建议在性能关键型应用程序中关注这些统计数据。 缓存统计信息可以使用基于pull或基于push的方法与报告系统集成。 基于pull的方法定期调用Cache.stats()并记录最新的快照。 基于push的方法提供自定义StatsCounter，以便在缓存操作期间直接更新指标。 有关使用Dropwizard Metrics的简单示例，请参阅stats-metrics。 如果使用Prometheus，可以查看simpleclient-caffeine。 你还可以使用Micrometer集成. Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 11:40:53 "},"caffeine/caches/cleanup.html":{"url":"caffeine/caches/cleanup.html","title":"清理","keywords":"","body":"清理 Caffeine缓存不会自动或在value过期后执行清理和驱逐value。相反,如果写操作很少,则在写操作之后或者读操作之后偶尔执行少量的维护。这个维护会委托给后台的Excutor,默认情况下ForkJoinPool.commonPool()，可以通过Caffeine.executor(Executor)覆盖。 原因如下：如果我们想持续缓存维护,我们需要在每个操作上锁定数据结构或者创建一个线程。一些环境限制了线程的创建，这会使Caffeine无法使用。 相反，我们把这个选择放在你的手中。如果您的缓存是高吞吐量的，那么您不必担心执行缓存维护来清理过期的条目等。如果您的缓存读取和写入很少，您可能希望创建自己的维护线程，定期调用cache.cleanUp()。 如果您想要定期对缓存进行常规缓存维护，只需很少的操作，例如使用ScheduledExecutorService安排维护。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 14:24:06 "},"caffeine/caches/policy.html":{"url":"caffeine/caches/policy.html","title":"策略","keywords":"","body":"策略 缓存支持的策略在构建时是固定的.在运行时，可以检查和调整该配置。 这些策略是通过一个Optional来获得的，以指示缓存是否支持该功能。 基于size cache.policy().eviction().ifPresent(eviction -> { eviction.setMaximum(2 * eviction.getMaximum()); }); 如果缓存受最大权重限制，则可以使用weightedSize()来获取当前权重。 这与报告存在条目数的Cache.estimatedSize()不同。 最大size或权重可以从getMaximum()或取，并使用setMaximum(long)进行调整。 调整后缓存将被驱逐，直到它在新的阈值内。 如果需要最有可能保留或驱逐的条目的子集，则hottest(int)和clodest(int)方法提供条目的有序快照。 基于时间 cache.policy().expireAfterAccess().ifPresent(expiration -> ...); cache.policy().expireAfterWrite().ifPresent(expiration -> ...); cache.policy().expireVariably().ifPresent(expiration -> ...); cache.policy().refreshAfterWrite().ifPresent(expiration -> ...); ageOf(key，TimeUnit)提供了从expireAfterAccess，expireAfterWrite或refreshAfterWrite策略的角度来看条目已经空闲的时间。 最大持续时间可以从getExpiresAfter(TimeUnit)获取，并使用setExpiresAfter（long，TimeUnit）进行调整。 如果需要最有可能保留或过期的条目的子集，youngest(int)和oldest(int)方法提供条目的有序快照。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 14:41:04 "},"caffeine/caches/testing.html":{"url":"caffeine/caches/testing.html","title":"测试","keywords":"","body":"测试 FakeTicker ticker = new FakeTicker(); // Guava's testlib Cache cache = Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .executor(Runnable::run) .ticker(ticker::read) .maximumSize(10) .build(); cache.put(key, graph); ticker.advance(30, TimeUnit.MINUTES) assertThat(cache.getIfPresent(key), is(nullValue()); 测试定时驱逐不要求测试等到挂钟时间结束。 使用Ticker接口和Caffeine.ticker（Ticker）方法在缓存builder中指定时间源，而不必等待系统时钟。 Guava的testlib为此提供了一个方便的FakeTicker。 Caffeine将定期维护，移除通知和异步计算委托给Executor。 这通过默认使用ForkJoinPool.commonPool()来提供更可预测的响应时间。 使用Caffeine.executor（Executor）方法在缓存构建器中指定直接（相同的线程）执行程序，而不必等待异步任务完成。 我们推荐使用Awaitility进行多线程测试。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 14:52:38 "},"caffeine/caches/faq.html":{"url":"caffeine/caches/faq.html","title":"常见问题","keywords":"","body":"常见问题 固定条目 固定条目是无法通过驱逐策略删除的条目。 当条目是一个有状态的资源（如锁）时，这是非常有用的，只有在客户端完成使用后才能将其丢弃。 在这些情况下，驱逐一个条目并重新计算它的行为会导致资源泄漏。 通过使权重和评估条目的权重为0，可以从最大size驱逐中排除条目。 然后成员不计入整体容量，并被最大size驱逐跳过。 必须定义自定义Weigher，用于评估条目是否被固定。 一个条目可以通过使用Long.MAX_VALUE的持续时间（大约300年）来排除。 自定义Expiry必须定义，用于评估条目是否固定。 将条目写入高速缓存时评估权重和到期时间。 这可以通过使用cache.asMap().compute来实现绑定pin和unpin。 递归计算 在原子操作内执行的加载，计算或回调可能不会写入缓存。 ConcurrentHashMap不允许这些递归写操作，并可能导致livelock（Java 8）或IllegalStateException（Java 9）。 解决方法是异步执行计算，例如使用AsyncLoadingCache。 在这种情况下映射已经建立，值是一个CompletableFuture，并且计算在缓存的原子范围之外执行。 如果发生无序的依赖链，这可能仍会发生死锁。 写竞争 Caffeine可能发生竞争的情况是，当前正在计算的条目的数量与高速缓存曾经包含的最大条目数量相似或者大于该条目的最大数量。这对应于当前计算条目接近底层ConcurrentHashMap的总容量，这阻止了调整map大小，直到加载函数完成。 缓存正在预热时(虽然可能根本没有)可能会发生。正在进行的计算的数量与缓存的容量相似的情况在小型缓存中可能更为明显。如果您观察到由于此类问题而导致的竞争（显示为在不同的请求阻塞在ConcurrentHashMap中的同一个锁上），请考虑将初始容量增加到预期的最大并发量以补偿,或使用异步缓存。 ConcurrentHashMap的内部文档中描述了一个很好的经验法则， 两个线程访问不同元素的锁争用概率在随机哈希下约为1 /（8 *元素）。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 15:40:03 "},"caffeine/extensions/simulator.html":{"url":"caffeine/extensions/simulator.html","title":"扩展","keywords":"","body":"模拟器 模拟器包括一系列驱逐策略和distribution generators。 这有助于调查策略是否适合使用场景。 用法 指定所需的配置后，在IDE中运行模拟器。或者，在命令行中运行gradlew simulator:run。 以下跟踪格式受支持。 仓库 大小 Location LIRS small git repository UCSD small git repository ARC large author's homepage UMass large UMass Storage WikiBench large WikiBench 报告示例 由于批量和广播，在独立运行每个策略时，时间是可比的。 策略 命中率 命中次数(hits) 未命中次数(misses) 请求次数(requests) 驱逐数量(Evictions) Steps 总共耗时(Time) opt.Clairvoyant 58.79% 9,323 6,535 15,858 6,035 ? 278.0ms sketch.WindowTinyLfu 56.11% 8,898 6,960 15,858 6,460 15,858 (100 %) 315.2 ms irr.Lirs 55.97% 8,876 6,982 15,858 6,482 27,689 (174 %) 311.0 ms adaptive.Arc 49.39% 7,833 8,025 15,858 7,525 15,858 (100 %) 166.3 ms linked.Lru 46.51% 7,375 8,483 15,858 7,983 15,858 (100 %) 128.2 ms linked.Fifo 40.72% 6,457 9,401 15,858 8,901 15,858 (100 %) 163.6 ms Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 16:53:48 "},"caffeine/extensions/jcache.html":{"url":"caffeine/extensions/jcache.html","title":"JCache","keywords":"","body":"JCache JSR-107 JCache是一个标准化的缓存API,与Java EE 6兼容，并在JEE 8中引入。 Caffeine提供了一个本地内存中的实现.JCache提供使用Typesafe Config库进行配置的配置。有关更多详细信息，请参阅reference.conf。 FactoryCreator可以被配置为将实例化委托给依赖注入框架。 JCache设计的ExpiryPolicy延迟到期的条目,并依靠最大size约束住区条目.该规范的做饭与Caffeine的本地支持不兼容,在定期维护期间,这些支持将在o(1)时间内尽快的到期.规范期望所有用途都有附加的大小限制,急事规范不支持该功能.当使用JCache的过期版本,而不是Caffeine的坏味道.应该使用size的边界来避免内存泄漏,并及时通知监听者。 注解支持 Spring 查看Spring文档 从Spring Framework 4.3和Spring Boot 1.4开始支持Caffeine。可以查看Spring Cache. Guice 使用Guice注入的话: compile 'org.jsr107.ri:cache-annotations-ri-guice:1.1.0' Injector injector = Guice.createInjector(new CacheAnnotationsModule()); CDI compile 'org.jsr107.ri:cache-annotations-ri-cdi:1.1.0' Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 18:06:16 "},"caffeine/extensions/guava.html":{"url":"caffeine/extensions/guava.html","title":"Guava","keywords":"","body":"Guava // Guava's LoadingCache interface LoadingCache graphs = CaffeinatedGuava.build( Caffeine.newBuilder().maximumSize(10_000), new CacheLoader() { // Guava's CacheLoader @Override public Graph load(Key key) throws Exception { return createExpensiveGraph(key); } }); Api兼容性 Caffeine提供了一个适配器去暴露guava接口的使用。 这些适配器提供了与下面的实施注意事项相同的API契约。 在可能的情况下，Guava喜欢的行为可以通过Guava的测试套件mock和验证。 当转换到Caffeine的接口，请注意，虽然两个缓存有相似的方法名称，行为可能会有所不同。 请咨询JavaDoc以更彻底地比较用法。 最大size(或权重) Guava将在使用LRU算法达到最大size之前逐出。 Caffeine使用Window TinyLFU算法，一旦超过阈值，就会被驱逐出去。 即时到期 Guava为了立即到期(expireAfterAccess(0, timeUnit) and expireAfterWrite(0, timeUnit)),转换为将最大size设置为0。这会导致移除通知其移除的原因是因为size而不是因为到期.Caffeine可以正确的识别移除原因. 替换通知 Guava会在任何更新条目时通知移除监听器.Caffeine在引用等于以前的值和替换值时不会发出通知. invalidation并发 Guava会在invalidation时会忽略条目，但是这些条目仍在计算中.Caffeine在每个条目被invalidation时将阻塞调用者,直到它完成计算,然后将被删除. 但是,计算条目可能被invalidateAll()忽略,因为这些key被底层散列表所限制.如果使用异步缓存,则invalidation是非阻塞的,因为不完整的future将被删除,并且移除通知被委托给计算线程。 异步维护 在写入和读取操作期间,Guava将在调用现场上分摊维护工作.Caffeine将此定期维护委托给配置的Excutor(默认ForkJoinPool.commonPool()).在调用现场上调用一个显示的cleanUp(); 异步通知 Guava可以从一个队列中使用任何调用现场处理移除通知。 Caffeine委托给配置的Excutor（默认：ForkJoinPool.commonPool（））。 异步刷新 Guava在请求刷新的线程上重新计算一个条目.Caffeine委托给配置的Excutor(默认:ForkJoinPool.commonPool()). 计算null值 Guava会在计算出NULL值时抛出异常,如果计算是刷新引起的保留原来条目.Caffeine返回Null值,并且如果计算是刷新引起的会删除条目.如果使用Guava试用期,用Guava CacheLoader构建Caffeine，Caffeine的行为就会跟Guava一样。 计算Map 21.0之前的Guava版本继承了非原子的ConcurrentMap默认方法（compute，computeIfAbsent，computeIfPresent和merge）。 Caffeine实现这些Java 8的方法并添加的原子版本。 CacheStats Guava的CacheStats.loadExceptionCount（）和CacheStats.loadExceptionRate（）分别在Caffeine中重命名为CacheStats.loadFailureCount（）和CacheStats.loadFailureRate（）。 这种变化是由于空值计算值被视为加载失败而不是例外。 Android和GWT兼容性 由于不支持Java 8的平台，Caffeine不提供兼容性。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 17:37:15 "},"caffeine/extensions/clhm.html":{"url":"caffeine/extensions/clhm.html","title":"ConcurrentLinkedHashMap","keywords":"","body":"ConcurrentLinkedHashMap 计算 ConcurrentLinkedHashMap继承了非原子的ConcurrentMap默认方法（compute，computeIfAbsent，computeIfPresent和merge）。 Caffeine实现这些Java 8方法并添加的原子版本。 权重 就像Guava一样ConcurrentLinkedHashMap要求最小权重为1，Caffeine允许最小权重为0，以表示基于size的策略时不会被驱逐。 异步通知 ConcurrentLinkedHashMap可能从调用线程队列中的任何线程处理驱逐通知。 Caffeine委托给配置的执行器（默认：ForkJoinPool.commonPool（））。 快照视图 ConcurrentLinkedHashMap以保留顺序支持快照视图。 Caffeine在Policy.Eviction中提供了此功能，通过Cache.policy（）获取，其中ascendingMapWithLimit按最冷升序，descendingMapWithLimit按最热降序。 序列化 ConcurrentLinkedHashMap在序列化时保留条目并丢弃驱逐顺序。 Caffeine像Guava一样，只保留配置并没有数据。 Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-08 18:23:11 "},"caffeine/performance/design.html":{"url":"caffeine/performance/design.html","title":"性能","keywords":"","body":"设计 访问顺序队列 双向链表对散列表中的所有条目进行排序。一个条目可以在O(1)时间内在hash map中找到,然后操作其相邻元素。 创建,更新或读取条目是顺序访问的。Least Recently Used（即LRU算法)的条目。most Recently used(即最热)的在尾部。这种结构是对于基于size(maximumSize)的驱逐和基于时间(expireAfterAccess)的驱逐的支持,这种结构所面临的挑战是每一次访问都需要这个列表的变化，而这个列表本身不能被有效地同时执行(线程不安全)。 写顺序队列 创建或更新条目是顺序写入的。 与访问顺序队列类似，写入顺序队列在O(1)时间内运行。 该队列用于生存时间到期（expireAfterWrite）。 Hierarchical TimerWheel 时间感知优先级队列使用散列和双向链表执行O(1)时间复杂度的操作。 此队列用于变量到期（expireAfter（Expiry））。 Read buffer 缓存操作的典型做法是给每次操作都加锁,以便安全的重新排列访问队列中的条目.另外一种方法是将每个重新排序操作存储在缓冲区中并批量更改.这可以被视为内存页替换策略的预写日志.当缓冲区满时,尝试获取锁并执行挂起的操作,但是如果已经挂起,则该线程可以立即返回。 读取缓冲区被实现为striped ring buffer(条带化的环形缓冲区,有关环形缓冲区的详情可以查看这里)。 stripe用于减少竞争，通过特定于线程的散列选择stripe。 环形缓冲区是一个固定大小的数组，使其高效并最小化垃圾收集开销。 stripe的数量可以根据竞争检测算法动态增长。 Write buffer 与Read buffer类似,此buffer用于replay write事件。read buffer允许有损的,因为这些事件被用来优化驱逐策略的命中率.wirte是不允许有丢失的,所以它必须作为一个有效的有界队列来实现.由于每次填充write buffer的优先级,它通常保持是空或者非常小的容量。 缓冲区被实现为一个可扩展的环形数组，可以调整到最大容量。当一个数组调整时新的数组被分配和生成。旧的数组包含消费者便利的转发连接,然后允许将旧数组解除分配.通过使用这种组块机制,缓冲区具有较小的初始size，较低的读写成本,并且产生最小的垃圾.当缓冲区已满并且不能再扩大时,生产者不断旋转重拾该数组,并试图安排维护工作,然后再短时间内完成该工作.这样做可以允许消费者线程优先,并通过重放驱逐策略上的写入来清空缓冲区。 lock amortization 虽然传统的缓存是通过锁定每一个操作来执行微量的工作,但是caffeine是通过分批工作将成本分摊到多个线程中的。这种做法将会分摊锁定状态的性能损耗而不是增加锁竞争的成本。尽管如果任务被拒绝的话或者调用者运行策略被使用,那么它可以由用户线程执行,但是这种维护低性能损耗的任务将委托给配置的Excutor。 由于锁的独占特性,缓冲区在给定的时间内只能被单个线程消耗。通过利用cpu高速缓存效率,这样就允许使用更高效的基于多生产者/消费的缓冲器实现，它也更好的符合硬件特性。 条目状态转换 高速缓存未被独占锁保护时的挑战是操作可能被记录并以错误的顺序重放.由于竞争，创建 - 读取 - 更新 - 删除序列可能不以相同顺序存储在缓冲器中。 要做到这一点将需要粗粒锁，从而降低性能。 正如在并发数据结构中一样，caffeine使用原子状态转换解决了这个困境。 一个条目可以有active，retired，或者dead状态。 active状态意味着它存在于散列表和存取/写入队列中。 从哈希表中删除条目时，将其标记为retired，需要从队列中删除。 发生这种情况时，条目被认为是dead，并有资格进行垃圾回收。 relaxed读写 Caffeine非常小心地使用每一个volatile操作.内存屏障不是从语言来实现volatile read和write的,而是由硬件来保证.通过了解哪些屏障被发射,以及它们对硬件和数据可见性的影响，存在实现更好性能的潜力。 Caffeine使用relaxed的读取时,锁可以保证独占访问,因为数据可见性可以由锁获取到的内存屏障提供.发生数据竞争也是可以接受的，例如当检查一个条目是否已经过期以模拟缓存未命中。 Caffeine以类似relaxed writes的方式来读取.如果条目使用锁来独占写,那么写入可以发生在解锁时发射的内存屏障上。 有时候也可以接受write skew，例如当读取条目时更新访问时间戳。 驱逐策略 Caffeine使用Window TinyLfu策略来提供接近最佳的命中率. 访问队列被分成两个空间：一个eden空间，如果被TinyLfu收容政策所接受，则会被驱逐到main空间。 TinyLfu估计eden区的条目和main区条目的频率，选择保留最高的历史使用条目。 频率计数存储在一个4位的CountMinSketch中，每个缓存条目需要8个字节才是准确的。 这种配置使得缓存能够在O(1)时间内以较小的占用空间基于频率和就近成度被驱逐。 Fastpath 当缓存低于其最大容量的50％时，驱逐策略尚未完全启用。 频率草图不初始化以减少内存占用，因为高速缓存可能被人为赋予较高的阈值。 除非另一个功能要求，否则不会记录访问，以避免争用读缓冲区，并在排空时重放访问。 哈希碰撞和Dos攻击保护 当key具有相同的散列码或散列到相同的位置时，可能会利用这些冲突来降低性能。 哈希表通过从链接列表降级到红黑树的来解决这个问题，并且CountMinSketch使用随机加载因子来保护其哈希函数。 对TinyLFU的攻击是利用碰撞来人为地提高驱逐政策条目的预估频率。 这导致所有新的到期条目被频率过滤器拒绝，从而使缓存无效。 一个解决方案是引入少量的抖动，这样可以使预估是不确定的。 这是通过随机接纳具有中等频率的被拒绝候选人的1％来完成的。 装饰哈希map //TEB Copyright © www.gitbook.com/@vitzhou 2016 all right reserved，powered by Gitbook该文件修订时间： 2018-02-11 09:59:03 "}}